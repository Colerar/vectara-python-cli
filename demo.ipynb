{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the unofficial Python SDK for [Vectara](https://vectara.com)'s RAG platform\n",
    "\n",
    "For questions, ask forrest@vectara.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘testdoc’: File exists\n",
      "--2023-11-21 18:37:52--  https://www.cs.jhu.edu/~jason/papers/mei+al.icml20.pdf\n",
      "Resolving www.cs.jhu.edu (www.cs.jhu.edu)... 128.220.13.64\n",
      "Connecting to www.cs.jhu.edu (www.cs.jhu.edu)|128.220.13.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2087657 (2.0M) [application/pdf]\n",
      "Saving to: ‘testdoc/neural_datalog_through_time.pdf’\n",
      "\n",
      "testdoc/neural_data 100%[===================>]   1.99M  3.89MB/s    in 0.5s    \n",
      "\n",
      "2023-11-21 18:37:53 (3.89 MB/s) - ‘testdoc/neural_datalog_through_time.pdf’ saved [2087657/2087657]\n",
      "\n",
      "--2023-11-21 18:37:53--  https://docs.vectara.com/assets/files/vectara_employee_handbook-4524365135dc70a59977373c37601ad1.pdf\n",
      "Resolving docs.vectara.com (docs.vectara.com)... 2600:1f18:16e:df01::64, 2600:1f18:2489:8200::c8, 54.161.234.33, ...\n",
      "Connecting to docs.vectara.com (docs.vectara.com)|2600:1f18:16e:df01::64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 53575 (52K) [application/pdf]\n",
      "Saving to: ‘testdoc/vectara.pdf’\n",
      "\n",
      "testdoc/vectara.pdf 100%[===================>]  52.32K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-11-21 18:37:53 (386 KB/s) - ‘testdoc/vectara.pdf’ saved [53575/53575]\n",
      "\n",
      "--2023-11-21 18:37:53--  https://raw.githubusercontent.com/TexteaInc/funix-doc/main/Reference.md\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35949 (35K) [text/plain]\n",
      "Saving to: ‘testdoc/funix.md’\n",
      "\n",
      "testdoc/funix.md    100%[===================>]  35.11K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-11-21 18:37:54 (2.52 MB/s) - ‘testdoc/funix.md’ saved [35949/35949]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get some test data \n",
    "!mkdir testdoc \n",
    "!wget https://www.cs.jhu.edu/~jason/papers/mei+al.icml20.pdf -O testdoc/neural_datalog_through_time.pdf \n",
    "!wget https://docs.vectara.com/assets/files/vectara_employee_handbook-4524365135dc70a59977373c37601ad1.pdf -O testdoc/vectara.pdf\n",
    "!wget https://raw.githubusercontent.com/TexteaInc/funix-doc/main/Reference.md -O testdoc/funix.md\n",
    "# !wget https://raw.githubusercontent.com/tangxyw/RecSysPapers/main/Calibration/Posterior%20Probability%20Matters%20-%20Doubly-Adaptive%20Calibration%20for%20Neural%20Predictions%20in%20Online%20Advertising.pdf -O testdoc/Calibration.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a client object \n",
    "\n",
    "By default, the constructor will look for the following environment variables:\n",
    "* VECTARA_CUSTOMER_ID\n",
    "* VECTARA_CLIENT_ID\n",
    "* VECTARA_CLIENT_SECRET\n",
    "\n",
    "Or you can manually pass them to the constructor, like the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearer/JWT token generated. It will expire in 30 minutes. To-regenerate, please call acquire_jwt_token(). \n"
     ]
    }
   ],
   "source": [
    "from keys import customer_id, client_id, client_secret\n",
    "# keys.py is as follows\n",
    "# customer_id = 'your customer id'\n",
    "# client_id = 'your client id'\n",
    "# client_secret = 'your client secret'\n",
    "\n",
    "client = vectara.vectara(customer_id, client_id, client_secret)\n",
    "# Default to environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_id = client.create_corpus(\"test_corpus\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset Corpus (when needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting corpus 9 successful. \n"
     ]
    }
   ],
   "source": [
    "# corpus_id = 9 # manual set here \n",
    "client.reset_corpus(corpus_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add files to a corpus\n",
    "\n",
    "You can use the `upload()` method to upload a file, a list of files, or a folder to a corpus. The `upload()` method automatically detects the type of file source to switch between the three methods below.\n",
    "* `upload_file()`: upload a single file\n",
    "* `upload_files()`: upload a list of files\n",
    "* `upload_folder()`: upload all files in a folder\n",
    "\n",
    "Of course, if you are very sure about what you are doing, you can also use the three methods above directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPOload switch: ./testdoc\n",
      "Uploading files from folder: ./testdoc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading...:   0%|          | 0/3 [00:00<?, ?it/s, ./testdoc/neural_datalog_through_time.pdf]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading invidiv8id\n",
      "Uploading..../testdoc/neural_datalog_through_time.pdf "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading...:  33%|███▎      | 1/3 [00:09<00:19,  9.54s/it, ./testdoc/funix.md]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. \n",
      "Uploading invidiv8id\n",
      "Uploading..../testdoc/funix.md "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading...:  67%|██████▋   | 2/3 [00:11<00:05,  5.18s/it, ./testdoc/vectara.pdf]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. \n",
      "Uploading invidiv8id\n",
      "Uploading..../testdoc/vectara.pdf "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading...: 100%|██████████| 3/3 [00:14<00:00,  4.69s/it, ./testdoc/vectara.pdf]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_id = 9 # manually set corpus_id if needed. \n",
    "client.upload(corpus_id, './testdoc', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query to a corpus and beautifully display the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful. \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Here is the answer\n",
       "To rearrange objects, you can follow these steps: \n",
       "1. Initialize the embeddings of the objects to 0 and recompute them in parallel for a certain number of iterations [1].\n",
       "2. Change the order and orientation of the objects using the \"direction\" attribute in a Funix decorator [3].\n",
       "3. Consider the topological order of the objects and wait until the upstream nodes have \"converged\" before working on a specific component [5].\n",
       "4. Embeddings of entities and relations that reflect selected past events can also aid in rearranging objects [4]. \n",
       "\n",
       "Please note that these steps are based on the search results provided and may not cover all possible approaches.\n",
       "\n",
       "### References:\n",
       "    \n",
       "1. From document **neural_datalog_through_time.pdf** (matchness=0.65684634):\n",
       "  _...This method recomputes all embeddings in parallel,\n",
       "and repeats this for some number of iterations...._\n",
       "\n",
       "2. From document **neural_datalog_through_time.pdf** (matchness=0.6553048):\n",
       "  _...Within each strongly connected component C, ini-\n",
       "tialize the embeddings to 0 and then recompute them in\n",
       "parallel for |C| iterations...._\n",
       "\n",
       "3. From document **funix.md** (matchness=0.65107906):\n",
       "  _...You can change their order and orientation using the \"direction\" attribute in a Funix decorator...._\n",
       "\n",
       "4. From document **neural_datalog_through_time.pdf** (matchness=0.6380951):\n",
       "  _...® Embeddings of entities and relations\n",
       "that reﬂect selected past events (§2.4 and §2.6)...._\n",
       "\n",
       "5. From document **neural_datalog_through_time.pdf** (matchness=0.6360733):\n",
       "  _...In the general case, visiting the com-\n",
       "ponents in topologically sorted order means that we wait to\n",
       "work on component C until its strictly upstream nodes have\n",
       "“converged,” so that the limited iterations on C make use of\n",
       "the best available embeddings of the upstream nodes...._\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = client.query(corpus_id, \"What should I do to rearrange objects?\")\n",
    "_ = vectara.post_process_query_result(answer, jupyter_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful. \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Here is the answer\n",
       "Yes, you can bring friends to the office. Some companies even have special events like \"Furry Friend Fridays\" [1] where you can introduce your pets via video conference. However, it is important to understand any specific policies or peculiarities regarding bringing friends to the office [2]. Additionally, there may be team-building activities or interactions involving exotic pets to enhance communication and inject fun into the workplace [3]. These interactions can add a colorful flair to team meetings [4]. Overall, while the sentiment of bringing friends to the office is appreciated, it is advisable to be aware of any rules or guidelines set by your company [2].\n",
       "\n",
       "### References:\n",
       "    \n",
       "1. From document **vectara.pdf** (matchness=0.6796313):\n",
       "  _...monthly \"Furry Friend Fridays\" where you can introduce your pets via video conference...._\n",
       "\n",
       "2. From document **vectara.pdf** (matchness=0.63029546):\n",
       "  _...However, before you bring in your pet parrot or rescue raven, there are some\n",
       "peculiarities to this policy that you must understand...._\n",
       "\n",
       "3. From document **vectara.pdf** (matchness=0.62800384):\n",
       "  _...The Team-building Adventures: From velociraptor training simulations to bear dance-offs, our\n",
       "exotic pet interactions are designed to build teamwork, enhance communication, and inject fun\n",
       "into the workplace...._\n",
       "\n",
       "4. From document **vectara.pdf** (matchness=0.6266819):\n",
       "  _...Plus, they add a colorful ﬂair to team meetings...._\n",
       "\n",
       "5. From document **vectara.pdf** (matchness=0.6225399):\n",
       "  _...We appreciate the sentiment, and we're sure your furry\n",
       "friends are delightful...._\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = client.query(corpus_id, \"Can I bring friends to the office?\")\n",
    "_ = vectara.post_process_query_result(answer, jupyter_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful. \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Here is the answer\n",
       "The returned results did not contain sufficient information to be summarized into a useful answer for your query. Please try a different search or restate your query differently.\n",
       "\n",
       "### References:\n",
       "    \n",
       "1. From document **neural_datalog_through_time.pdf** (matchness=0.684738):\n",
       "  _...We take λh(t) to be the\n",
       "(Poisson) intensity of h at time t:  that is, it models the\n",
       "limit as dt → 0+ of the expected rate of h on the interval\n",
       "[t, t + dt) (i.e., the expected number of occurrences of h\n",
       "divided by dt)...._\n",
       "\n",
       "2. From document **neural_datalog_through_time.pdf** (matchness=0.6802496):\n",
       "  _...In the continuous-time case, we evaluate (8) at\n",
       "                rm\n",
       "time s to obtain [h]<-   ∈ R7Dh (so Wr needs to have more\n",
       "                                                  rm\n",
       "rows), and accordingly obtain 7 vectors in (0, 1)Dh,..._\n",
       "\n",
       "3. From document **neural_datalog_through_time.pdf** (matchness=0.67772794):\n",
       "  _...We then set (f ; i; z) =def\n",
       "σ([h]<-  )...._\n",
       "\n",
       "4. From document **funix.md** (matchness=0.6768694):\n",
       "  _...There will be a radio box on the front end for the user to switch between the two display options at any time, and the JSON Viewer will be used by default...._\n",
       "\n",
       "5. From document **funix.md** (matchness=0.6706363):\n",
       "  _...If sessions are not properly maintained, you can use two Funix functions to manually set and get a session-level global variable...._\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = client.query(corpus_id, \"How to set the frequency?\")\n",
    "_ = vectara.post_process_query_result(answer, jupyter_display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
